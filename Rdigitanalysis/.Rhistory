get_p_value = function(observed_mean, stimulated_mean){
p_values = data.frame(matrix(nrow=1, ncol=length(observed_mean)))
colnames(p_values) = colnames(observed_mean)
combined_mean_data = rbind(observed_mean, stimulated_mean)
for (i in 1:length(observed_mean)){
#combine observed and stimulated and find rank of observed
#first row is observation --> first index
p_values[i] = rank(-combined_mean_data[[i]])[1] / length(combined_mean_data[,i])
}
return(p_values)
}
#' Perform a single padding test. Helper function for \code{padding_test}.
#'
#' @inheritParams padding_test
#'
#' @return A list of padding test results for input data from \code{digitdata}.
single_padding_test = function(digitdata, contingency_table, data_columns, max_length, num_digits, N, omit_05, category, plot){
#get benford mean in each digit place
Benford = get_benford_mean(contingency_table, omit_05)
Benford_mean = Benford$Benford_mean
contingency_table = Benford$contingency_table
######################################################
#handle the data_columns = 'all' situation
data_columns = get_data_columns(digitdata, data_columns)
#get combined by rows data for all data columns needed
combined_data = combine_by_columns(digitdata, data_columns, indexes=NA)
#get expected and observed mean in each digit position
lst = get_expected_mean(digitdata, combined_data, Benford_mean, max_length, num_digits)
freq_table=lst$freq_table
expected_mean = lst$expected_mean
rownames(expected_mean) = 'All'
observed_mean = get_observed_mean(lst$final_data, num_digits)
rownames(observed_mean) = 'All'
#get the difference in expected and observed mean in each digit position
diff_in_mean = observed_mean - expected_mean
rownames(diff_in_mean) = 'All'
#Monte Carlo Stimulation of N datasets and get mean
stimulated_mean = Benford_stimulation(N, freq_table, expected_mean, contingency_table)
#get p values by comparing with stimulation
p_values = get_p_value(observed_mean, stimulated_mean)
rownames(p_values) = 'All'
######################################################
#break out by category
if (!(is.na(category))){
#get indexes for each category
indexes_of_categories = break_by_category(digitdata@cleaned, category) #this is a list since unequal number of entries for each category
#break by category for all
for (category_name in names(indexes_of_categories)){
indexes_of_category = indexes_of_categories[[category_name]]
######################################################
#get combined by rows data for all data columns needed
combined_data_of_category = combine_by_columns(digitdata, data_columns, indexes=indexes_of_category)
#get expected and observed mean in each digit position
lst = get_expected_mean(digitdata, combined_data_of_category, Benford_mean, max_length, num_digits)
freq_table=lst$freq_table
expected_mean[category_name, ] = lst$expected_mean
observed_mean[category_name, ] = get_observed_mean(lst$final_data, num_digits)
#get the difference in expected and observed mean in each digit position
diff_in_mean[category_name, ]  = observed_mean[category_name, ] - expected_mean[category_name, ]
#Monte Carlo Stimulation of N datasets and get mean
stimulated_mean = Benford_stimulation(N, freq_table, expected_mean[category_name, ], contingency_table)
#get p values by comparing with stimulation
p_values[category_name, ] = get_p_value(observed_mean[category_name, ], stimulated_mean)
######################################################
}
}
return(list(diff_in_mean=diff_in_mean, p_values=p_values))#, expected_mean=expected_mean, observed_mean=observed_mean))
}
#' Performs padding test vs stimulations of Benford conforming datasets via percentile
#'
#' @param max_length The length of the longest numbers considered. Defaulted to 8.
#' @param num_digits The total number of digits aligned from the right to be analyzed. Defaulted to 5, meaning analyzing digit place 1s to 10ks.
#' @param N The number of Benford conforming datasets to stimulate.
#' @inheritParams all_digits_test
#' @inheritParams sector_test
#'
#' @return
#' \itemize{
#'   \item A list with 4 elements
#'   \itemize{
#'     \item \code{expected_mean}: the expected mean by Benford's Law
#'     \item \code{observed_mean}: the mean of the input data
#'     \item \code{diff_in_mean}: the mean difference betweeen observed_mean and expected_mean
#'     \item \code{p_values}: the percentile of the observed dataset among all stimulated datasets in decreasing order
#'   }
#'   \item Plots on \code{diff_in_mean} for each category if \code{plot = TRUE}
#' }
#' @export
#'
#' @examples
#' padding_test(digitdata, contingency_table, data_columns='all', break_out='col_name')
#' padding_test(digitdata, contingency_table, data_columns=c('col_name1', 'col_name2'), omit_05=NA)
#' padding_test(digitdata, contingency_table, data_columns='all', max_length=7, num_digits=3, omit_05=0, category='category_name', category_grouping=list(...))
#' padding_test(digitdata, contingency_table, data_columns='all', N=100, omit_05=NA, break_out='col_name', category='category_name', category_grouping=list(...))
padding_test = function(digitdata, contingency_table, data_columns='all', max_length=8, num_digits=5, N=10000, omit_05=c(0,5), break_out=NA, category=NA, plot=TRUE){
#check input
input_check(digitdata=digitdata, contingency_table=contingency_table, data_columns=data_columns, omit_05=omit_05,
break_out=break_out, max_length=max_length, num_digits=num_digits, N=N, category=category)
#list of results from all break out category to be returned
padding_test_results = list()
#perform padding test on all data
result = single_padding_test(digitdata, contingency_table, data_columns, max_length, num_digits, N, omit_05, category, plot)
padding_test_results[['All']] = result
if (plot){
#2D histogram
if (is.na(category)){
print(hist_2D(result$diff_in_mean, data_style='row', xlab='Digit Place', ylab='Deviation from Mean', title=paste('Padding Test', 'All', sep='_'), hline=NA, hline_name=''))
}
#Multi-variable 2D histogram
else {
print(hist_2D_variables(result$diff_in_mean, data_style='row', xlab='Digit Place', ylab='Deviation from Mean', title=paste('Padding Test', 'All', sep='_')))
}
}
#perform padding test on all break out categories
if (!(is.na(break_out))){
#get indexes for each category
indexes_of_categories = break_by_category(data=digitdata@cleaned, break_out=break_out) #this is a list since unequal number of entries for each category
#break by category for all
for (category_name in names(indexes_of_categories)){
indexes_of_category = indexes_of_categories[[category_name]]
#create a digitdata class for this category
digitdata_of_category = make_sub_digitdata(digitdata=digitdata, indexes=indexes_of_category)
#perform padding test on this category
result_of_category = single_padding_test(digitdata, contingency_table, data_columns, max_length, num_digits, N, omit_05, category, plot)
padding_test_results[[category_name]] = result_of_category
if (plot){
#2D histogram
if (is.na(category)){
print(hist_2D(result_of_category$diff_in_mean, data_style='row', xlab='Digit Place', ylab='Deviation from Mean', title=paste('Padding Test', category_name, sep='_'), hline=NA, hline_name=''))
}
#Multi-variable 2D histogram
else {
print(hist_2D_variables(result_of_category$diff_in_mean, data_style='row', xlab='Digit Place', ylab='Deviation from Mean', title=paste('Padding Test', category_name, sep='_')))
}
}
}
}
return(padding_test_results)
}
break_out = 'DIST'
category='SECTOR'
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, plot=TRUE)
result
DigitData@cleaned
DigitData@cleaned['SECTOR']
unique(DigitData@cleaned['SECTOR'])
a=unique(DigitData@cleaned['SECTOR'])
a[1]
a[[1]]
b=list()
c=a[[1]]
c
b[[c[1]]]= c[1]
b
for (i in c){print(i)}
############################################################
#Testing for sector test
#Wenjun Chang
#Summer 2020
############################################################
#############prelim############
#clear workspace
rm(list = ls())
#free up R memory
gc()
##############################
#general functions
#load data input functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\data_input_functions.R')
#load functions for computing Benford table
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\Benford_table_functions.R')
#load all plotting functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\plotting_functions.R')
#load input check function
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\input_check_function.R')
############################
#testing
#load helper functions for all digit test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\all_digit_test_helper_functions.R')
#load all functions for repeat test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\repeat_test.R')
#load all functions for sector test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\sector_test.R')
#test with data
#load data input functions
data_columns = c("ALEXP.Values")
fp = 'C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\ARID MASTER FINAL.csv'
DigitData = make_class(filepath = fp, col_analyzing = data_columns)
contingency_table = load_Benford_table('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\contingency_table.csv')
#DigitData has to drop all columns with NA in ALEXP.Values
indexes_with_valid_alexp_values = which(!(is.na(DigitData@cleaned$ALEXP.Values)))
DigitData = make_sub_digitdata(DigitData, indexes_with_valid_alexp_values)
#test sector test
break_out ='DIST'
category = 'SECTOR'
duplicate_matching_cols = c("ALEXP.Values", "YEAR", "DIST", "SECTOR")
category_grouping = NA#list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
result = sector_test(DigitData, category, category_grouping, duplicate_matching_cols, break_out, failure_factor=3)
order = c('Mandera', 'Isiolo', 'Baringo', 'Ijara', 'Wajir', 'Garissa', 'Samburu', 'Marsabit', 'Moyale', 'Turkana', 'Tana', 'All')
result[order, ]
result
############################################################
#Functions for digit analysis R package
###repeat test functions in this file
#Wenjun Chang
#Summer 2020
############################################################
####failure factor
#' Performs sector test to analyze uneven distribution of percent repeats across sectors (supposed to be uniform).
#' A wrapper function for \code{repeat_test}.
#'
#' @param category The column for splitting the data into sectors for separate analysis. The second division (usually variables) shown in plots.
#' @param category_grouping A list of arrays, or defaulted to NA.
#' \itemize{
#'   \item Each the names of the elements in the list is the category name
#'   \item Each array contains the values belonging to that category
#'   \item If it is remain as NA as default, while \{category} is not NA, then \code{category_grouping} will default to every individual item in
#'   \code{category} will be in a separate group.
#' }
#' @param failure_factor NEED TO EDIT LATER
#' @inheritParams repeat_test
#'
#' @return
#' \itemize{
#'   \item A table of p-values for repeat test by sector on each category
#'   \item Plots for each break out element with variables as categories specified by \code{category_grouping} if \code{plot = TRUE}
#'   \item If NaN is in returned table, it means that there are no occurances of the data of the sector in that category --> 0/0 in percentage
#' }
#' @export
#'
#' @examples
#' sector_test(digitdata, category='sector_name', category_grouping=list('sector 1'=c('a'), 'sector 2'=c('b', 'c')))
#' sector_test(digitdata, category='sector_name', category_grouping=list('sector 1'=c('a, b'), 'sector 2'=c('c', 'd')),
#' duplicate_matching_cols=c('col_name1, col_name2'), break_out='col_name', failure_factor=3)
sector_test = function(digitdata, category, category_grouping=NA, duplicate_matching_cols='all', break_out=NA, failure_factor=3, plot=TRUE){
#check input
input_check(digitdata=digitdata, break_out=break_out, duplicate_matching_cols=duplicate_matching_cols, category=category, category_grouping=category_grouping, plot=plot)
#check if the sector columns are valid
if (is.na(match(category, colnames(digitdata@cleaned)))){
stop('specified column to break on second division is not a column in the data!')
}
else{
if (!(is.na(category_grouping))){
for (category_name in names(category_grouping)){
if (NA %in% match(category_grouping[[category_name]], unique(digitdata@cleaned[[category]]))){
print(category_name)
stop('specified category is not a category in the column break on second division!')
}
}
}
}
#handles if grouping is NA, while group is not
get_grouping = function(grouping, column, digitdata){
if (is.na(grouping)){
unique_items = unique(digitdata@cleaned[column])[[1]]
grouping = list()
for (item in unique_items){
grouping[[item]] = item
}
}
return(grouping)
}
category_grouping = get_grouping(grouping=category_grouping, column=category, digitdata=digitdata)
#initialize table to be returned
category_names = c()
if (!(is.na(break_out))){
category_names = names(break_by_category(digitdata@cleaned, break_out))
}
sector_repeats_table = data.frame(matrix(nrow = length(category_names)+1, ncol = 0)) # +1 (all)
rownames(sector_repeats_table) = c('All', category_names) #ensure each row is fixed for a category when append
#get indexes for each category in the specified sector column
sector_column_indexes = break_by_category(digitdata@cleaned, category) #this is a list since unequal number of entries for each category
for (sector_name in names(category_grouping)){
print(sector_name)
#get the index of sector by accessing the names of the categories in the data column that belong to this sector
indexes_of_sector = sector_column_indexes[category_grouping[[sector_name]]]
indexes_of_sector = unlist(indexes_of_sector) #turn into an array
#create new digitdata object for each sector
digitdata_of_sector = make_sub_digitdata(digitdata=digitdata, indexes=indexes_of_sector)
#repeats test
repeats_table = repeat_test(digitdata_of_sector, duplicate_matching_cols=duplicate_matching_cols, break_out=break_out)
#update table
print(repeats_table)
sector_repeats_table[sector_name] = NA
sector_repeats_table[sector_name][rownames(repeats_table), ] = repeats_table #match the rownames by using rownames
# return(list(a=sector_repeats_table, b=repeats_table))
print(sector_repeats_table)
}
#plot
if (plot){
print(hist_2D_variables(data.frame(sector_repeats_table), data_style='col', xlab='districts', ylab='percent repeats', title='Sector Effect Test'))
}
return(sector_repeats_table)
}
result = sector_test(DigitData, category, category_grouping, duplicate_matching_cols, break_out, failure_factor=3)
############################################################
#Testing for padding test
#Wenjun Chang
#Summer 2020
############################################################
#############prelim############
#clear workspace
rm(list = ls())
#free up R memory
gc()
##############################
#general functions
#load data input functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\data_input_functions.R')
#load functions for computing Benford table
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\Benford_table_functions.R')
#load all plotting functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\plotting_functions.R')
#load input check function
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\input_check_function.R')
############################
#testing
#load helper functions for all digit test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\all_digit_test_helper_functions.R')
#load all functions for padding test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\padding_test.R')
#test with data
#load data input functions
data_columns = c("ALEXP.Values")
fp = 'C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\ARID MASTER FINAL.csv'
DigitData = make_class(filepath = fp, col_analyzing = data_columns)
contingency_table = load_Benford_table('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\contingency_table.csv')
#DigitData has to drop all columns with NA in ALEXP.Values
indexes_with_valid_alexp_values = which(!(is.na(DigitData@cleaned$ALEXP.Values)))
DigitData = make_sub_digitdata(DigitData, indexes_with_valid_alexp_values)
#test padding test
data_columns = c("ALEXP.Values")#c("ALEXP")#,"BENTOT", "BENM", "BENF")
max_length = 7
num_digits = 5
N = 10 #120k datasets took 15 mins
omit_05 = c(0,5)
break_out = 'DIST'
category='SECTOR'
category_grouping = list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, plot=TRUE)
result
category_grouping = list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, category_grouping=category_grouping, plot=TRUE)
############################################################
#Testing for padding test
#Wenjun Chang
#Summer 2020
############################################################
#############prelim############
#clear workspace
rm(list = ls())
#free up R memory
gc()
##############################
#general functions
#load data input functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\data_input_functions.R')
#load functions for computing Benford table
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\Benford_table_functions.R')
#load all plotting functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\plotting_functions.R')
#load input check function
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\input_check_function.R')
############################
#testing
#load helper functions for all digit test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\all_digit_test_helper_functions.R')
#load all functions for padding test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\padding_test.R')
#test with data
#load data input functions
data_columns = c("ALEXP.Values")
fp = 'C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\ARID MASTER FINAL.csv'
DigitData = make_class(filepath = fp, col_analyzing = data_columns)
contingency_table = load_Benford_table('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\contingency_table.csv')
#DigitData has to drop all columns with NA in ALEXP.Values
indexes_with_valid_alexp_values = which(!(is.na(DigitData@cleaned$ALEXP.Values)))
DigitData = make_sub_digitdata(DigitData, indexes_with_valid_alexp_values)
#test padding test
data_columns = c("ALEXP.Values")#c("ALEXP")#,"BENTOT", "BENM", "BENF")
max_length = 7
num_digits = 5
N = 10 #120k datasets took 15 mins
omit_05 = c(0,5)
break_out = 'DIST'
category= 'SECTOR'
category_grouping = list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, category_grouping=category_grouping, plot=TRUE)
result
break_out = NA#'DIST'
category= 'SECTOR'
category_grouping = NA#list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, category_grouping=category_grouping, plot=TRUE)
category= NA#'SECTOR'
category_grouping = list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, category_grouping=category_grouping, plot=TRUE)
result
break_out = 'DIST'
category= NA#'SECTOR'
category_grouping = list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, category_grouping=category_grouping, plot=TRUE)
result
############################################################
#Testing for padding test
#Wenjun Chang
#Summer 2020
############################################################
#############prelim############
#clear workspace
rm(list = ls())
#free up R memory
gc()
##############################
#general functions
#load data input functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\data_input_functions.R')
#load functions for computing Benford table
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\Benford_table_functions.R')
#load all plotting functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\plotting_functions.R')
#load input check function
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\input_check_function.R')
############################
#testing
#load helper functions for all digit test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\all_digit_test_helper_functions.R')
#load all functions for padding test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\padding_test.R')
#test with data
#load data input functions
data_columns = c("ALEXP.Values")
fp = 'C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\ARID MASTER FINAL.csv'
DigitData = make_class(filepath = fp, col_analyzing = data_columns)
contingency_table = load_Benford_table('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\contingency_table.csv')
#DigitData has to drop all columns with NA in ALEXP.Values
indexes_with_valid_alexp_values = which(!(is.na(DigitData@cleaned$ALEXP.Values)))
DigitData = make_sub_digitdata(DigitData, indexes_with_valid_alexp_values)
#test padding test
data_columns = c("ALEXP.Values")#c("ALEXP")#,"BENTOT", "BENM", "BENF")
max_length = 7
num_digits = 5
N = 1 #120k datasets took 15 mins
omit_05 = c(0,5)
break_out = 'DIST'
category= 'SECTOR'
category_grouping = list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, category_grouping=category_grouping, plot=TRUE)
result
############################################################
#Testing for padding test
#Wenjun Chang
#Summer 2020
############################################################
#############prelim############
#clear workspace
rm(list = ls())
#free up R memory
gc()
##############################
#general functions
#load data input functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\data_input_functions.R')
#load functions for computing Benford table
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\Benford_table_functions.R')
#load all plotting functions
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\plotting_functions.R')
#load input check function
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\input_check_function.R')
############################
#testing
#load helper functions for all digit test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\all_digit_test_helper_functions.R')
#load all functions for padding test
source('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\Rdigitanalysis\\R\\padding_test.R')
#test with data
#load data input functions
data_columns = c("ALEXP.Values")
fp = 'C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\ARID MASTER FINAL.csv'
DigitData = make_class(filepath = fp, col_analyzing = data_columns)
contingency_table = load_Benford_table('C:\\Users\\happy\\OneDrive - California Institute of Technology\\Desktop\\digitanalysis\\contingency_table.csv')
#DigitData has to drop all columns with NA in ALEXP.Values
indexes_with_valid_alexp_values = which(!(is.na(DigitData@cleaned$ALEXP.Values)))
DigitData = make_sub_digitdata(DigitData, indexes_with_valid_alexp_values)
#test padding test
data_columns = c("ALEXP.Values")#c("ALEXP")#,"BENTOT", "BENM", "BENF")
max_length = 7
num_digits = 5
N = 100000 #120k datasets took 15 mins
omit_05 = c(0,5)
break_out = 'DIST'
category= 'SECTOR'
category_grouping = list(Training_and_Transport=c("TRN", "TRAVEL", "VEHICLES"), Civil_Works=c("CW"), Goods_and_Equipment=c("GE"))
#match the data with Jetson's
result = padding_test(digitdata=DigitData, contingency_table=contingency_table, data_columns=data_columns, max_length=max_length,
num_digits=num_digits, N=N, omit_05=omit_05, break_out=break_out, category=category, category_grouping=category_grouping, plot=TRUE)
result
